# ğŸ“š ORNN â€“ Pipeline d'Analyse Documentaire Intelligent

ORNN est une maquette fonctionnelle dâ€™un pipeline dâ€™analyse documentaire modulaire, fondÃ© exclusivement sur des technologies **open source**. Il vise Ã  extraire, reformuler, thÃ©matiser et restructurer l'information contenue dans des documents administratifs, techniques ou contractuels, en fournissant en sortie un **livrable structurÃ©**.

Ce projet a pour but de valider une approche orientÃ©e produit, dans une optique de publication en open source. Une version "forkÃ©e" propriÃ©taire pourra ensuite Ã©voluer dans un cadre commercial.

---

## ğŸ§© Vue d'ensemble des modules

Le pipeline ORNN est organisÃ© en **4 modules principaux**, exÃ©cutÃ©s dans lâ€™ordre suivant :

| Ã‰tape | Nom du module | Description |
|------:|----------------|-------------|
| 1ï¸âƒ£ | **HEXGATE** | Ingestion des documents bruts (TXT) et segmentation en phrases enrichies de mÃ©tadonnÃ©es. |
| 2ï¸âƒ£ | **EKKO** | PrÃ©traitement linguistique et sÃ©mantique : nettoyage, reformulation, normalisation, enrichissement. |
| 3ï¸âƒ£ | **KALISTA** | Application de tags thÃ©matiques selon 3 mÃ©thodes : mots-clÃ©s, rÃ¨gles mÃ©tier, modÃ¨le ML. |
| 4ï¸âƒ£ | **AURELION** | Regroupement des phrases, reformulation finale et gÃ©nÃ©ration dâ€™un livrable HTML structurÃ©. |

---

## ğŸ› ï¸ Technologies et bibliothÃ¨ques

- **NLP / IA :**
  - `spaCy` (segmentation, lemmatisation, dÃ©tection de mots inconnus)
  - `sentence-transformers` (vectorisation sÃ©mantique)
  - `scikit-learn` (modÃ¨les ML)
  - `nlpaug` (paraphrasing)
  - `transformers` (paraphrasing LLM pour la version avancÃ©e)

- **Web et UI :**
  - `streamlit` pour l'interface utilisateur
  - `jinja2` pour les templates HTML du livrable

- **Outillage & persistance :**
  - `joblib` pour la persistance des modÃ¨les
  - `json` pour tous les formats dâ€™Ã©change

---

## ğŸš€ Lancer l'application

### 1. CrÃ©ation de lâ€™environnement

```bash
cd Project_ORNN_clean
python3 -m venv .venv
source .venv/bin/activate


2. Installation des dÃ©pendances

pip install -r requirements.txt
python -m spacy download fr_core_news_sm


3. Lancer l'application Streamlit
streamlit run app/main.py


âš™ï¸ FonctionnalitÃ©s par module
ğŸ§Š HEXGATE
Nettoyage du texte brut

Segmentation en phrases

DÃ©tection des dates

Identification des mots inconnus

ğŸŒ€ EKKO
PrÃ©traitement structural et grammatical

Application dâ€™un thÃ©saurus

Paraphrasing (simple + avancÃ©)

PrÃ©paration des phrases pour le tagging

ğŸ·ï¸ KALISTA
Matching sur mots-clÃ©s avec themes_collectivites.json

Tagging via rÃ¨gles mÃ©tier (rules_thematiques_kalista.json)

Classification ML via un modÃ¨le de logreg entraÃ®nÃ© avec sentence-transformers

ğŸ§© AURELION
SÃ©lection de la meilleure reformulation

Regroupement des phrases par thÃ¨me

RÃ©Ã©criture finale

GÃ©nÃ©ration dâ€™un livrable HTML stylisÃ© via jinja2


-----------------

ğŸ“Œ Bonnes pratiques
SÃ©parer les modules : chaque transformation est isolÃ©e, testable, rÃ©utilisable.

Garder la logique dâ€™enchaÃ®nement claire (HEXGATE > EKKO > KALISTA > AURELION)

Utiliser un thÃ©saurus et des rÃ¨gles mÃ©tiers comme garde-fous avant tout ML.

Utiliser les modules comme briques de construction (framework modulaire).



-------------------
ğŸ“œ Licence & publication
Ce projet est Ã  publier sous licence open source permissive (MIT ou Apache 2.0).
Une version produit dÃ©rivÃ©e pourra Ãªtre construite par fork, avec interface renforcÃ©e et intÃ©gration back-end.

-------------------
ConÃ§u par : Hadi ABDALLAH 
