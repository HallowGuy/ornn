
import streamlit as st
import json
import re

def clean_text(text):
    # Nettoyage simple : suppression de ponctuation, espaces multiples, minuscules
    text = re.sub(r"[\n\r\t]", " ", text)
    text = re.sub(r"[^a-zA-ZÃ€-Ã¿0-9\s]", "", text)  # garder lettres, chiffres, accents
    text = re.sub(r"\s+", " ", text)
    return text.strip().lower()

def run_ekko():
    st.subheader("ğŸ“„ EKKO â€“ Nettoyage de phrases extraites")

    uploaded_file = st.file_uploader("ğŸ“¥ Charger un JSON issu de HEXGATE", type=["json"])
    
    if uploaded_file:
        raw_data = json.load(uploaded_file)
        phrases = raw_data.get("content", [])
        
        st.success(f"âœ… {len(phrases)} phrases chargÃ©es depuis {raw_data['metadata'].get('document_name', 'Document')}")

        cleaned_phrases = []
        for entry in phrases:
            original = entry["text"]
            cleaned = clean_text(original)
            cleaned_phrases.append({
                "original": original,
                "nettoyÃ©": cleaned
            })

        st.markdown("### ğŸ§¹ RÃ©sultat du nettoyage")
        for i, item in enumerate(cleaned_phrases):
            st.markdown(f"**Phrase {i+1}**")
            st.code(f"Avant : {item['original']}")
            st.code(f"AprÃ¨s : {item['nettoyÃ©']}")

        final_output = {
            "metadata": raw_data.get("metadata", {}),
            "nettoyage": "standard",
            "content": [
                {"phrase_number": i+1, "text_cleaned": item["nettoyÃ©"], "text_original": item["original"]}
                for i, item in enumerate(cleaned_phrases)
            ]
        }

        st.markdown("### ğŸ“¦ JSON nettoyÃ© final :")
        st.json(final_output)

        json_data = json.dumps(final_output, indent=2, ensure_ascii=False)
        st.download_button("ğŸ“¤ TÃ©lÃ©charger le JSON nettoyÃ©", data=json_data, file_name="ekko_output.json", mime="application/json")
